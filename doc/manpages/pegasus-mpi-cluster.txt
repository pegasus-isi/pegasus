pegasus-mpi-cluster(1)
======================
:doctype: manpage


Name
----
pegasus-mpi-cluster - a tool for running computational workflows expressed as DAGs
(Directed Acyclic Graphs) on computational clusters using MPI.


Synopsis
--------
[verse]
*pegasus-mpi-cluster* [*-h*][*-v*][*-q*][*-s*][*-o* 'path'][*-e* 'path'] 
                    [*-m* 'M'][*-t* 'T'][*-n*][*-r*] 'workflow.dag'


Description
-----------
*pegasus-mpi-cluster* is a tool used to run HTC (High Throughput Computing) scientific
workflows on systems designed for HPC (High Performance Computing).
Many HPC systems have custom architectures that are optimized for
tightly-coupled, parallel applications. These systems commonly have
exotic, low-latency networks that are designed for passing short 
messages very quickly between compute nodes. Many of these networks are so
highly optimized that the compute nodes do not even support a TCP/IP
stack. This makes it impossible to run HTC applications using software
that was designed for commodity clusters, such as Condor.

*pegasus-mpi-cluster* was developed to enable loosely-coupled HTC applications such as
scientific workflows to take advantage of HPC systems. In order to get
around the network issues outlined above, *pegasus-mpi-cluster* uses MPI (Message
Passing Interface), a commonly used API for writing SPMD (Single
Process, Multiple Data) parallel applications. Most HPC systems have an
MPI implementation that works on whatever exotic network architecture
the system uses.

An *pegasus-mpi-cluster* job consists of a single master process (this process is rank
0 in MPI parlance) and several worker processes. The master process
manages the workflow and assigns workflow tasks to workers for execution. 
The workers execute the tasks and return the results to the master. Any 
output written to stdout or stderr by the tasks is captured (see 
<<TASK_STDIO,*TASK STDIO*>>).

*pegasus-mpi-cluster* applications are expressed as DAGs (Directed Acyclic Graphs)
(see <<DAG_FILES,*DAG FILES*>>). Each node in the graph represents a task, 
and the edges represent dependencies between the tasks that constrain the 
order in which the tasks are executed. Each task is a program and a set of
parameters that need to be run (i.e. a command and some optional 
arguments). The dependencies typically represent data flow dependencies in
the application, where the output files produced by one task are needed
as inputs for another.

If an error occurs while executing a DAG that causes the workflow to
stop, it can be restarted using a rescue file, which records the
progress of the workflow (see <<RESCUE_FILES,*RESCUE FILES*>>). This 
enables *pegasus-mpi-cluster* to pick up running the workflow where it stopped.

*pegasus-mpi-cluster* allows applications expressed as a DAG to be executed in 
parallel on a large number of compute nodes. It is designed to be simple,
lightweight and robust.


Options
-------
*-h*::
*--help*::
    Print help message

*-v*::
*--verbose*::
    Increase logging verbosity. Adding multiple *-v* increases the
    level more. The default log level is 'INFO'. (see <<LOGGING,
    *LOGGING*>>)

*-q*::
*--quiet*::
    Decrease logging verbosity. Adding multiple *-q* decreases the
    level more. The default log level is 'INFO'. (see <<LOGGING,
    *LOGGING*>>)

*-s*::
*--skip-rescue*::
    Ignore the rescue file for 'workflow.dag' if it exists. Note that
    *pegasus-mpi-cluster* will still create a new rescue file for the 
    current run. The default behavior is to use the rescue file if one 
    is found. (see <<RESCUE_FILES,*RESCUE FILES*>>)

*-o* 'path'::
*--stdout* 'path'::
    Path to file for task stdout. (see <<TASK_STDIO,*TASK STDIO*>>)

*-e* 'path'::
*--stderr* 'path'::
    Path to file for task stderr. (see <<TASK_STDIO,*TASK STDIO*>>)

*-m* 'M'::
*--max-failures* 'M'::
    Stop submitting new tasks after 'M' tasks have failed. Once 'M' 
    has been reached, *pegasus-mpi-cluster* will finish running any tasks that have
    been started, but will not start any more tasks. This option is
    used to prevent *pegasus-mpi-cluster* from continuing to run a workflow that 
    is suffering from a systematic error, such as a missing binary or
    an invalid path. The default for 'M' is 0, which means unlimited 
    failures are allowed.

*-t* 'T'::
*--tries* 'T'::
    Attempt to run each task 'T' times before marking the task as failed.
    Note that the 'T' tries do not count as failures for the purposes of the
    *-m* option. A task is only considered failed if it is tried 'T' times
    and all 'T' attempts result in a non-zero exitcode. The value of 'T' must 
    be at least 1. The default is 1.

*-n*::
*--nolock*::
    Do not lock DAGFILE. By default, *pegasus-mpi-cluster* will attempt to acquire
    an exclusive lock on DAGFILE to prevent multiple MPI jobs from running the same
    DAG at the same time. If this option is specified, then the lock will not be
    acquired.

*-r*::
*--rescue* 'path'::
    Path to rescue log. If the file exists, and *-s* is not specified, then 
    the log will be used to recover the state of the workflow. The file is truncated
    after it is read and a new rescue log is created in its place. The default is to
    append '.rescue' to the DAG file name. (see <<RESCUE_FILES,*RESCUE FILES*>>)

[[DAG_FILES]]
DAG Files
---------
*pegasus-mpi-cluster* workflows are expressed using a simple text-based format similar
to that used by Condor DAGMan. There are only two record types allowed
in a DAG file: *TASK* and *EDGE*. Any blank lines in the DAG (lines with
all whitespace characters) are ignored, as are any lines beginning with
# (note that # can only appear at the beginning of a line, not in the
middle).

The format of a *TASK* record is:
[verse]
    *TASK* 'id' 'executable' ['arguments...']

Where 'id' is the ID of the task, 'executable' is the path to the executable
or script to run, and 'arguments...' is a space-separated list of
arguments to pass to the task. An example is:
------------
    TASK t01 /bin/program -a -b
------------
The format of an *EDGE* record is:
[verse]
    *EDGE* 'parent' 'child'

Where 'parent' is the ID of the parent task, and 'child' is the ID of the
child task. An example *EDGE* record is:
------------
    EDGE t01 t02
------------
A simple diamond-shaped workflow would look like this:
------------
    # diamond.dag
    TASK A /bin/echo "I am A"
    TASK B /bin/echo "I am B"
    TASK C /bin/echo "I am C"
    TASK D /bin/echo "I am D"

    EDGE A B
    EDGE A C
    EDGE B D
    EDGE C D
------------


[[RESCUE_FILES]]
Rescue Files
------------
Many different types of errors can occur when running a DAG. One or
more of the tasks may fail, the MPI job may run out of wall time,
*pegasus-mpi-cluster* may segfault (we hope not), the system may crash, etc. In order
to ensure that the DAG does not need to be restarted from the beginning
after an error, *pegasus-mpi-cluster* generates a rescue file for each workflow.

The rescue file is a simple text file that lists all of the tasks in
the workflow that have finished successfully. This file is updated each
time a task finishes, and is flushed periodically so that if the work-
flow fails and the user restarts it, *pegasus-mpi-cluster* can determine which tasks
still need to be executed. As such, the rescue file is a sort-of trans-
action log for the workflow.

The rescue file contains zero or more DONE records. The format of these
records is:
[verse]
    *DONE* 'taskid'

Where 'taskid' is the ID of the task that finished successfully.

By default, rescue files are named 'DAGNAME.rescue' where 'DAGNAME' is the
path to the input DAG file. The file name can be changed by specifying the
*-r* argument.


[[LOGGING]]
Logging
-------
By default, all logging messages are printed to stderr. If you turn up
the logging using *-v* then you may end up with a lot of stderr being
forwarded from the workers to the master.

The log levels in order of severity are: FATAL, ERROR, WARN, INFO, DEBUG, 
and TRACE.

The default logging level is INFO. The logging levels can be
increased with *-v* and decreased with *-q*.


[[TASK_STDIO]]
Task STDIO
----------
By default the stdout and stderr of tasks will be redirected to the master's
stdout and stderr. You can change the path of these files with the *-o* and 
*-e* arguments. Note that the stdio of all workers will be merged into one 
out and one err file by the master at the end, so I/O from different workers 
will not be interleaved, but I/O from each worker will appear in the order 
that it was generated. Also note that, if the job fails for any reason, the outputs 
will not be merged, but instead there will be one file for each worker 
named DAGFILE.MPID.out.X and DAGFILE.MPID.err.X, where DAGFILE is the path to
the input DAG, MPID is the master's process ID, and 'X' is the worker's rank.


Misc
----
Resource Utilization
~~~~~~~~~~~~~~~~~~~~
At the end of the workflow run, the master will report the resource
utilization of the job. This is done by adding up the total runtimes
of all the tasks executed (including failed tasks) and dividing by
the total wall time of the job times N, where N is both the total 
number of processes including the master, and the total number of
workers. These two resource utilization values are provided so that
users can get an idea about how efficiently they are making use of
the resources they allocated. Low resource utilization values suggest
that the user should use fewer cores, and longer wall time, on future 
runs, while high resource utilization values suggest that the user 
could use more cores for future runs and get a shorter wall time.


Known Issues
------------
fork() and exec()
~~~~~~~~~~~~~~~~~
In order for the worker processes to start tasks on the compute
node the compute nodes must support the *fork()* and *exec()* system
calls. If your target machine runs a stripped-down OS on the
compute nodes that does not support these system calls, then
*pegasus-mpi-cluster* will not work.

CPU Usage
~~~~~~~~~
Many MPI implementations are optimized so that message sends and
receives do not block. The reasoning is that blocking adds over-
head and, since many HPC systems use space sharing on dedicated
hardware, there are no other processes competing, so spinning
instead of blocking can produce better performance. On those
MPI implementations the master and worker processes will run at
100% CPU usage even when they are waiting. If this is a problem
on your system, then there are some MPI implementations that
'do' block on message send and receive. To test *pegasus-mpi-cluster*, for
example, we use MPICH2 with the ch3:sock device instead of the
ch3:nemesis device to avoid this issue.


Author
------
Gideon Juve `<gideon@isi.edu>`

Mats Rynge `<rynge@isi.edu>`
