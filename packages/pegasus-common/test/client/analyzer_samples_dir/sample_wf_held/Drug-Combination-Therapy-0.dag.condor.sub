# Filename: hierarchical-workflow-0.dag.condor.sub
# Generated by condor_submit_dag hierarchical-workflow-0.dag 
universe	= scheduler
executable	= /usr/bin/condor_dagman
getenv		= True
output		= hierarchical-workflow-0.dag.lib.out
error		= hierarchical-workflow-0.dag.lib.err
log		= hierarchical-workflow-0.dag.dagman.log
remove_kill_sig	= SIGUSR1
+OtherJobRemoveRequirements	= "DAGManJobId =?= $(cluster)"
# Note: default on_exit_remove expression:
# ( ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
# attempts to ensure that DAGMan is automatically
# requeued by the schedd if it exits abnormally or
# is killed (e.g., during a reboot).
on_exit_remove	= (ExitSignal =?= 11 || (ExitCode =!= UNDEFINED && ExitCode >=0 && ExitCode <= 2))
copy_to_spool	= False
arguments	= "-p 0 -f -l . -Lockfile hierarchical-workflow-0.dag.lock -AutoRescue 1 -DoRescueFrom 0 -Dag hierarchical-workflow-0.dag -MaxPost 20 -Suppress_notification -CsdVersion $CondorVersion:' '10.2.0' '2023-01-05' 'BuildID:' '621409' 'PackageID:' '10.2.0-1' '$ -Dagman /usr/bin/condor_dagman"
environment	= _CONDOR_DAGMAN_LOG=/home/mzalam/028-dynamic-hierarchy/work/mzalam/pegasus/hierarchical-workflow/run0005/hierarchical-workflow-0.dag.dagman.out
transfer_input_files=rrr
transfer_output_files=xxx
executable=/usr/bin/pegasus-dagman
+pegasus_wf_uuid="36fe624e-e43d-40c8-9d27-38e7c0eae3f6"
+pegasus_root_wf_uuid="36fe624e-e43d-40c8-9d27-38e7c0eae3f6"
+pegasus_wf_name="hierarchical-workflow-0"
+pegasus_wf_time="20230111T062302-0800"
+pegasus_version="5.0.3dev"
+pegasus_job_class=11
+pegasus_cluster_size=1
+pegasus_site="local"
+pegasus_execution_sites="CCG,local"
+pegasus_wf_xformation="pegasus::dagman"
environment	= "_CONDOR_DAGMAN_LOG=hierarchical-workflow-0.dag.dagman.out"
queue